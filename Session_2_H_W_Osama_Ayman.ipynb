{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIwZsU0haNkj"
   },
   "source": [
    "## Task 1 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45wCuSvgajao"
   },
   "source": [
    "### Build SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JwcbnqiymCE3"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8HITwTqnJcX"
   },
   "source": [
    "### Read the json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "93iqAB7tnMYQ"
   },
   "outputs": [],
   "source": [
    "data=spark.read.json('DataFrames_sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNx0qMfunbKX"
   },
   "source": [
    "### Display the schema:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UG4CcVJenc9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- D: double (nullable = true)\n",
      " |-- H: double (nullable = true)\n",
      " |-- HDD: string (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- RAM: string (nullable = true)\n",
      " |-- ScreenSize: string (nullable = true)\n",
      " |-- W: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zaj0nHTcngEF"
   },
   "source": [
    "### Get all the data when \"Model\" equal \"MacBook Pro\":\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vm9QPKBCnkuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('*').where(F.col('Model')=='MacBook Pro').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43oLte9LuGzA"
   },
   "source": [
    "### Create TempView:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nVFYFcjtdIGW"
   },
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCLMmjRLdjbT"
   },
   "source": [
    "### Display \"RAM\"column and count \"RAM\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BxykutRjuF0X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Ram|\n",
      "+----+\n",
      "|16GB|\n",
      "| 8GB|\n",
      "| 8GB|\n",
      "|64GB|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Ram from view').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5nlwq4t9gvK"
   },
   "source": [
    "### Get all columns when \"Year\" column equal \"2015\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WXxjFxN19hJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from view where Year=2015').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHjK2Kqfuv24"
   },
   "source": [
    "### Get all when \"Model\" start with \"M\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "m30EkY_iu1Gs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "|7.74|0.52|256GB SSD|  2|    MacBook| 8GB|       12\"|11.04|  2.03|2016|\n",
      "|8.94|0.68|128GB SSD|  3|MacBook Air| 8GB|     13.3\"| 12.8|  2.96|2016|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from view where Model LIKE 'M%' \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igw9iqJQ7TdH"
   },
   "source": [
    "### Get all data when \"Model\" column equal \"MacBook Pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SRCGSB_W9cPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|      Model| RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "|9.48|0.61|512GB SSD|  1|MacBook Pro|16GB|       15\"|13.75|  4.02|2015|\n",
      "+----+----+---------+---+-----------+----+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from view where Model = 'MacBook Pro' \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZIlmJidw1Ep"
   },
   "source": [
    "### Get all data with Multiple Conditions when \"RAM\" column equal \"8GB\" and \"Model\" column is \"Macbook\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-5T7roxgnBBV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "|   D|   H|      HDD| Id|  Model|RAM|ScreenSize|    W|Weight|Year|\n",
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "|7.74|0.52|256GB SSD|  2|MacBook|8GB|       12\"|11.04|  2.03|2016|\n",
      "+----+----+---------+---+-------+---+----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from view where Model = 'MacBook' and RAM = '8GB' \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8YPAWQ8HxI"
   },
   "source": [
    "### Get all data with Multiple Conditions when \"D\" greater than or equal \"8\" and \"Model\" column is \"iMac\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XDHJSpQK9MuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "|  D|   H|    HDD| Id|Model| RAM|ScreenSize|   W|Weight|Year|\n",
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "|8.0|20.3|1TB SSD|  4| iMac|64GB|       27\"|25.6|  20.8|2017|\n",
      "+---+----+-------+---+-----+----+----------+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from view where Model = 'iMac' and D >= 8 \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d6364f6"
   },
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlWhDvTPfZgu"
   },
   "source": [
    "### Read \"test1\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7964d064"
   },
   "outputs": [],
   "source": [
    "data2=spark.read.csv('test1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.createOrReplaceTempView('view2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJKjDOKHfnCt"
   },
   "source": [
    "### Display Salary of the people less than or equal to 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "c21edffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Salary from view2 where Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvFWNFJjf0Pq"
   },
   "source": [
    "### Display Salary of the people less than or equal to 20000 and greater than or equal 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "26f76ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 18000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Salary from view2 where Salary between 15000 and 20000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VAcIXkTgN9D"
   },
   "source": [
    "## Task 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOeqRO2KgW34"
   },
   "source": [
    "### Read \"test3\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "4d3bd081"
   },
   "outputs": [],
   "source": [
    "data3=spark.read.csv('test3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejyUT1rngdeR"
   },
   "source": [
    "### Display dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "7ed791ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp42YtorghXJ"
   },
   "source": [
    "### Display schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "d57d24ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHxWeGCCgnww"
   },
   "source": [
    "### Group by \"Name\" column and using sum function on \"Name\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f15f8197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWgkaU3bhUOL"
   },
   "source": [
    "### Group by \"Name\" column and using avg function on \"Name\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "fc122ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     Name|       avg(salary)|\n",
      "+---------+------------------+\n",
      "|Sudhanshu|11666.666666666666|\n",
      "|    Sunny|            6000.0|\n",
      "|    Krish| 6333.333333333333|\n",
      "|   Mahesh|            3500.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.groupBy('Name').avg().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARg_-WPKhfL5"
   },
   "source": [
    "### Group by \"Departments\" column and using sum function on \"Departments\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "151d2264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7rdLSEXhn4W"
   },
   "source": [
    "### Group by \"Departments\" column and using mean function on \"Departments\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "66fe5552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.groupBy('Departments').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bndivgGjhsbq"
   },
   "source": [
    "### Group by \"Departments\" column and using count function on \"Departments\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "bc7bf192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfPs99wnhwGu"
   },
   "source": [
    "### Apply agg to using sum function get the total of salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "37b26cbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(salary)=73000)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.agg(F.sum('salary')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYD0wGPRi1FO"
   },
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJLc1PY1i-Np"
   },
   "source": [
    "You've been flown to their headquarters in Ulsan, South Korea, to assist them in accurately estimating the number of crew members a ship will need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PEoknoejL4r"
   },
   "source": [
    "They're currently building new ships for certain customers, and they'd like you to create a model and utilize it to estimate how many crew members the ships will require.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70slYH-tjR81"
   },
   "source": [
    "Metadata:\n",
    "1. Measurements of ship size \n",
    "2. capacity \n",
    "3. crew \n",
    "4. age for 158 cruise ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZzrhGnHkRCU"
   },
   "source": [
    "It is saved in a csv file for you called \"ITI_data.csv\". our task is to develop a regression model that will assist in predicting the number of crew members required for future ships. The client also indicated that they have found that particular cruise lines will differ in acceptable crew counts, thus this is most likely an important factor to consider when conducting your investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A9CZzWWqZnOC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---+-----------------+----------+------+------+-----------------+-----+\n",
      "|    Ship_name|    Cruise_line|Age|          Tonnage|passengers|length|cabins|passenger_density| crew|\n",
      "+-------------+---------------+---+-----------------+----------+------+------+-----------------+-----+\n",
      "|    Adventure|Royal_Caribbean| 12|            138.0|     31.14|  10.2| 15.57|            44.32|11.85|\n",
      "|      Allegra|          Costa| 21|            28.43|      8.08|  6.16|   4.1|            35.19|  4.0|\n",
      "|      Arcadia|            P&O|  9|             85.0|     19.68|  9.35|  9.84|            43.19| 8.69|\n",
      "|        Aries|           Star| 22|            3.341|      0.66|   2.8|  0.33|            50.62| 0.59|\n",
      "|      Armonia|            MSC| 12|             58.6|     15.66|  8.24|  7.83|            37.42|  7.0|\n",
      "|    Atlantica|          Costa| 13|           85.619|     21.14|  9.57| 10.56|             40.5|  9.2|\n",
      "|   Brilliance|Royal_Caribbean| 11|            90.09|     25.01|  9.62|  10.5|            36.02| 8.48|\n",
      "|    Caribbean|       Princess|  9|            116.0|      26.0|  9.51|  13.0|            44.62| 11.0|\n",
      "|  Celebration|       Carnival| 26|           47.262|     14.86|  7.22|  7.43|             31.8|  6.7|\n",
      "|      Century|      Celebrity| 18|70.60600000000001|      17.7|  8.15|  8.75|            39.89| 8.58|\n",
      "|        Cloud|      Silversea| 19|             16.8|      2.96|  5.14|  1.48|            56.76|  2.1|\n",
      "|     Conquest|       Carnival| 11|            110.0|     29.74|  9.53| 14.88|            36.99| 19.1|\n",
      "|Constellation|      Celebrity| 11|             91.0|     20.32|  9.65|  9.75|            44.78| 9.99|\n",
      "|        Coral|       Princess| 11|91.62700000000001|     19.74|  9.64|  9.87|            46.42|  9.0|\n",
      "|        Crown|      Norwegian| 25|            34.25|     10.52|  6.15|  5.26|            32.56|  4.7|\n",
      "|         Dawn|      Norwegian| 11|             90.0|      22.4|  9.65|  11.2|            40.18| 11.0|\n",
      "|         Dawn|       Princess| 16|           77.499|      19.5|  8.56|  10.5|            39.74|  9.0|\n",
      "|      Destiny|       Carnival| 17|          101.353|     26.42|  8.92| 13.21|            38.36| 10.0|\n",
      "|        Dream|      Norwegian| 21|            50.76|     17.48|  7.54|  8.74|            29.04| 6.14|\n",
      "|      Ecstasy|       Carnival| 22|           70.367|     20.52|  8.55|  10.2|            34.29|  9.2|\n",
      "+-------------+---------------+---+-----------------+----------+------+------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"ITI_data.csv\",header=True,inferSchema=True)\n",
    "trainDF, testDF = df.randomSplit([.8,.2],seed=42)\n",
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Tonnage', 'passengers', 'length', 'cabins', 'passenger_density']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs=[name for (name,dt) in df.dtypes if ((dt!='string')&(name!='crew')) ]\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QTNLhZSlf9_"
   },
   "source": [
    "### OneHotEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "-ZZxxxKLZnOF"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder,VectorAssembler\n",
    "stringIndexer= StringIndexer(inputCol='Cruise_line',outputCol='Cruise_line_index',handleInvalid='skip')\n",
    "one_hot_encoder= OneHotEncoder(inputCol='Cruise_line_index',outputCol='Cruise_line_ohe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNCxWem0l662"
   },
   "source": [
    "### Use VectorAssembler to merge all columns into one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "pE4ohNjVZnOG"
   },
   "outputs": [],
   "source": [
    "assemblerInputs.append('Cruise_line_ohe')\n",
    "vecAssembler= VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rbf56f6AmUUl"
   },
   "source": [
    "### Create a Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "nvqnqTkunkNx"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr=LinearRegression(featuresCol='features',labelCol='crew')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVdxQTcSC6Cz"
   },
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "UqM9HxkNIHwE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "pipline=Pipeline(stages=[stringIndexer,one_hot_encoder,vecAssembler,lr])\n",
    "piplineModel=pipline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = piplineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+----+------------------+\n",
      "|features                                                     |crew|prediction        |\n",
      "+-------------------------------------------------------------+----+------------------+\n",
      "|(24,[0,1,2,3,4,5,9],[13.0,61.0,13.8,7.8,6.88,44.2,1.0])      |6.0 |6.076991912972243 |\n",
      "|(24,[0,1,2,3,4,5,16],[29.0,45.0,11.78,7.54,5.3,38.2,1.0])    |5.2 |5.1508155313416255|\n",
      "|(24,[0,1,2,3,4,5,16],[13.0,76.0,18.74,8.86,9.39,40.55,1.0])  |8.5 |8.602341038488795 |\n",
      "|(24,[0,1,2,3,4,5,11],[22.0,52.926,13.02,7.18,6.54,40.65,1.0])|6.17|5.495541791006299 |\n",
      "|(24,[0,1,2,3,4,5,8],[7.0,116.0,31.0,9.51,15.57,37.42,1.0])   |12.0|12.889496273257695|\n",
      "+-------------------------------------------------------------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('features','crew','prediction').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEbfwhqeHOCc"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379745546359095"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluatore=RegressionEvaluator(labelCol='crew',predictionCol='prediction',metricName='rmse')\n",
    "rmse=evaluatore.evaluate(predDF)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SluXM6j-Gt9B"
   },
   "source": [
    "By Eng. Mostafa Nabieh \n",
    "If you have questions, please feel free to ask.\n",
    "\n",
    "My Email : nabieh.mostafa@yahoo.com\n",
    "\n",
    "My Whatsapp : +201015197566"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session 2 H.W.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
