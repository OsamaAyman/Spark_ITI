{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MrBC530gmg5"
   },
   "source": [
    "Let's start with your project: \n",
    "\n",
    "Are you a data scientist? \n",
    "\n",
    "I think you are an awesome a data scientist.\n",
    "\n",
    "### **Problem** \n",
    "**Our goal is to create a predictive model that can answer the following question:**\n",
    "\n",
    "**What kind of people had a better chance of surviving?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhBfwzBgioTD"
   },
   "source": [
    "**Data about passengers:**\n",
    "*   Name\n",
    "*   Age\n",
    "*   Gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIEH8iZqi-sk"
   },
   "source": [
    "## Install and Import Libraries\n",
    "Let's install PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oj1HhvIOY5Yz"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDp80mG9jmfU"
   },
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ttzML9fpjE5a"
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiqECDzLj1Mg"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn-hxNggkTqV"
   },
   "source": [
    "You have two datasets: \n",
    "* Train  \n",
    "* Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8-A8M7QmKDJ"
   },
   "source": [
    "Read two datasets: \n",
    "* Train\n",
    "* Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Mx2qAccBk15y"
   },
   "outputs": [],
   "source": [
    "train=spark.read.csv('train.csv',header= True,inferSchema=True)\n",
    "test=spark.read.csv('test.csv',header= True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2ANTnWmSCq"
   },
   "source": [
    "Let's work with train dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5mWJR30lNs5"
   },
   "source": [
    "**Confirm if this is a dataframe or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tEYTePrzk9yl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvLJElPrlT4i"
   },
   "source": [
    "**Show 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jYwhqvV8lnO0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QIYVxRXlnnw"
   },
   "source": [
    "**Display schema for the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pcvERiICl1Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmE3Wd80l1S6"
   },
   "source": [
    "**Statistical summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cNY0SItol5Mo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiFaIEQTl70_"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSNPOnP8mw2Q"
   },
   "source": [
    "**Display count for the train dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zrtpG11Fl9HM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_6nnTfxm9_x"
   },
   "source": [
    "**Can you answer this question:** \n",
    "\n",
    "**How many people survived, and how many didn't survive?** \n",
    "\n",
    "**Please save data in a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QDoqPwyomYxA"
   },
   "outputs": [],
   "source": [
    "survived=train.select(F.col('Survived')).where('Survived==0').count()\n",
    "not_survived=train.select(F.col('Survived')).where('Survived==1').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8DUtZXPn46m"
   },
   "source": [
    "**Display your result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0XHAK8ceoCMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of survived=  549\n",
      "number of didnt survived=  342\n"
     ]
    }
   ],
   "source": [
    "print('number of survived= ',survived)\n",
    "print('number of didnt survived= ',not_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygsg7wQqor9a"
   },
   "source": [
    "**Can you display your answer in ratio form?(Hint: Use \"UDF\" Function. (Hint: Use \"UDF\" Function. This is a hint you can use any method.)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3uiaN29PoQnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of survived ratio=  61.61616161616161\n",
      "number of didnt survived ratio=  38.38383838383838\n"
     ]
    }
   ],
   "source": [
    "print('number of survived ratio= ',(survived/(survived+not_survived))*100)\n",
    "print('number of didnt survived ratio= ',(not_survived/(survived+not_survived))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Aker_lp1h4"
   },
   "source": [
    "**Can you get the number of males and females?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XllkDlo3ongJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male=  577  female=  314\n"
     ]
    }
   ],
   "source": [
    "male=train.select(F.col('Sex')).filter(\"Sex=='male'\").count()\n",
    "female=train.select(F.col('Sex')).filter(\"Sex=='female'\").count()\n",
    "print('male= ',male, ' female= ',female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFaJ15zqtEV"
   },
   "source": [
    "**1. What is the average number of survivors of each gender?**\n",
    "\n",
    "**2. What is the number of survivors of each gender?**\n",
    "\n",
    "(Hint: Group by the \"sex\" column. This is a hint you can use any method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NUikH7MUqdKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   Sex|      avg(Survived)|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n",
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  233|\n",
      "|  male|  109|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('sex','Survived').groupBy('Sex').avg().show()\n",
    "train.select('sex','Survived').where('Survived==1').groupBy('Sex').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCEdYNdArtRN"
   },
   "source": [
    "**Create temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YjlK6HDUqsI5"
   },
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('train_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNePifnshHr"
   },
   "source": [
    "**How many people survived, and how many didn't survive? By SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "0HxfPRTMslqk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|survived|count_survived|\n",
      "+--------+--------------+\n",
      "|       1|           342|\n",
      "|       0|           549|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select survived,count(survived) as count_survived from train_temp group by(survived)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVCdY6EasFWV"
   },
   "source": [
    "**Can you display the number of survivors from each gender as a ratio?**\n",
    "\n",
    "(Hint: Group by \"sex\" column. This is a hint you can use any method.)\n",
    "\n",
    "**Can you do this via SQL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7xQc3pUUr3HF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   sex|      avg(survived)|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select sex, avg(survived) from train_temp group by (sex)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QXc5V8uu3Y"
   },
   "source": [
    "**Display a ratio for \"p-class\": SUM(Survived)/count for p-class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Mscs2mDFdFsD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Pclass|       pclass_ratio|\n",
      "+------+-------------------+\n",
      "|     1| 0.6296296296296297|\n",
      "|     3|0.24236252545824846|\n",
      "|     2|0.47282608695652173|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Pclass,(sum(survived)/count(Pclass)) as pclass_ratio from train_temp group by (Pclass)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0klxwAvg6J"
   },
   "source": [
    "**Let's take a break and continue after this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ctM9t8atxJl"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CfanZTCt6Wk"
   },
   "source": [
    "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8Nm8S1K0r4uY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=train.union(test)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI7AD8FLz3iO"
   },
   "source": [
    "**Display count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "s_WERAL8wvJa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R4Miuy0z_uP"
   },
   "source": [
    "**Can you define the number of null values in each column?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.na.df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBX8cJ000aqe"
   },
   "source": [
    "**Create Dataframe for null values**\n",
    "\n",
    "1. Column\n",
    "2. Number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ITmyUelNxjJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKrOi5a0-Ma"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVQlr9vDy7Y4"
   },
   "source": [
    "**Create Temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "xs3yeXhGI8rv"
   },
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('train_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txa8NZIO1JaP"
   },
   "source": [
    "**Can you show the \"name\" column from your temporary table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "m7yXqJoJy35k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|name                                                   |\n",
      "+-------------------------------------------------------+\n",
      "|Braund, Mr. Owen Harris                                |\n",
      "|Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |\n",
      "|Heikkinen, Miss. Laina                                 |\n",
      "|Futrelle, Mrs. Jacques Heath (Lily May Peel)           |\n",
      "|Allen, Mr. William Henry                               |\n",
      "|Moran, Mr. James                                       |\n",
      "|McCarthy, Mr. Timothy J                                |\n",
      "|Palsson, Master. Gosta Leonard                         |\n",
      "|Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |\n",
      "|Nasser, Mrs. Nicholas (Adele Achem)                    |\n",
      "|Sandstrom, Miss. Marguerite Rut                        |\n",
      "|Bonnell, Miss. Elizabeth                               |\n",
      "|Saundercock, Mr. William Henry                         |\n",
      "|Andersson, Mr. Anders Johan                            |\n",
      "|Vestrom, Miss. Hulda Amanda Adolfina                   |\n",
      "|Hewlett, Mrs. (Mary D Kingcome)                        |\n",
      "|Rice, Master. Eugene                                   |\n",
      "|Williams, Mr. Charles Eugene                           |\n",
      "|Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|\n",
      "|Masselmani, Mrs. Fatima                                |\n",
      "+-------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select name from train_temp').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F0F9cTZ2Cuz"
   },
   "source": [
    "**Run this code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "0kx6OcB-2BBT"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "combined = data.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "combined.createOrReplaceTempView('combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbZeUWS12r59"
   },
   "source": [
    "**Display \"Title\" column and count \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "hGkFMtlp1FAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Title|\n",
      "+------+\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|Master|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|Master|\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Title from combined').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBQDKYu4JOa"
   },
   "source": [
    "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "rjnx5l5r2Qaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|   Title|countTitle|\n",
      "+--------+----------+\n",
      "|     Mme|         1|\n",
      "|      Ms|         1|\n",
      "|     Don|         1|\n",
      "|Jonkheer|         2|\n",
      "|    Capt|         2|\n",
      "|    Lady|         2|\n",
      "|     Sir|         2|\n",
      "|Countess|         2|\n",
      "|   Major|         3|\n",
      "|     Col|         4|\n",
      "|    Mlle|         4|\n",
      "|     Rev|         9|\n",
      "|      Dr|        11|\n",
      "|  Master|        56|\n",
      "|     Mrs|       186|\n",
      "|    Miss|       257|\n",
      "|      Mr|       786|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_count=spark.sql('select Title,count(title) as countTitle from combined group by(title) ORDER by countTitle')\n",
    "title_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Don': 'rare',\n",
       " 'Mme': 'rare',\n",
       " 'Ms': 'rare',\n",
       " 'Countess': 'rare',\n",
       " 'Lady': 'rare',\n",
       " 'Capt': 'rare',\n",
       " 'Sir': 'rare',\n",
       " 'Jonkheer': 'rare',\n",
       " 'Major': 'rare',\n",
       " 'Col': 'rare',\n",
       " 'Mlle': 'rare',\n",
       " 'Rev': 'rare',\n",
       " 'Dr': 'rare',\n",
       " 'Master': 'Master',\n",
       " 'Mrs': 'Mrs',\n",
       " 'Miss': 'Miss',\n",
       " 'Mr': 'Mr'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_titles=list(map(lambda row: row.asDict(), title_count.collect()))\n",
    "titles_map={row['Title']:'rare' if row['countTitle']<56 else row['Title'] for row in list_titles }\n",
    "titles_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wrE95Cv7Oqh"
   },
   "source": [
    "**Run the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "HdDbWuDl7Pf4"
   },
   "outputs": [],
   "source": [
    "def impute_title(title):\n",
    "    return titles_map[title]# Title_map is your dictionary. please change this name with your dictionary name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5EQVIhK7a9R"
   },
   "source": [
    "**Apply the function on \"Title\" column using UDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "rBAiIOn77XFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|Master|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|Master|\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convertUDF = F.udf(lambda z: impute_title(z))\n",
    "converted_df=combined.select(convertUDF(F.col('title')).alias('title'))\n",
    "converted_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8ewllf7kiV"
   },
   "source": [
    "**Display \"Title\" from table and group by \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "J9sjQb084GU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| title|count|\n",
      "+------+-----+\n",
      "|  rare|   44|\n",
      "|  Miss|  257|\n",
      "|Master|   56|\n",
      "|    Mr|  786|\n",
      "|   Mrs|  186|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted_df.select('title').groupBy('title').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H45QNLj9vJp"
   },
   "source": [
    "## **Preprocessing Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwRAhumK-u__"
   },
   "source": [
    "**Based on the \"age\" column mean, you will fill in the missing age values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean=combined.select(F.avg('age')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPivde8_GI-"
   },
   "source": [
    "**Fill missing with \"age\" mean:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "eXYSVzvl4z63"
   },
   "outputs": [],
   "source": [
    "combined=combined.na.fill(age_mean,subset=['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGsnUz-m_P95"
   },
   "source": [
    "## **Preprocessing Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHbbamcXMSYP"
   },
   "source": [
    "**Select \"Embarked\" column, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "v-lRu5vc_FW7"
   },
   "outputs": [],
   "source": [
    "grouped_Embarked=combined.select('embarked').groupBy('embarked').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1qf5u2IOQrx"
   },
   "source": [
    "**Show \"groupped_Embarked\" your variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "jSFNDTNg_erb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|  111|\n",
      "|    null|    3|\n",
      "|       C|  253|\n",
      "|       S|  962|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQWYgKBMrbp"
   },
   "source": [
    "**Get max of groupped_Embarked:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "ZLYj4F7E_iqb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|       962|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked.select(F.max('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8vhoEs8N2w_"
   },
   "source": [
    "**Fill missing values with max 'S' of grouped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "LdzQCRud_mAa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25| null|       S|    Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|  C85|       C|   Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|  Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1| C123|       S|   Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05| null|       S|    Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583| null|       Q|    Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|  E46|       S|    Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075| null|       S|Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333| null|       S|   Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708| null|       C|   Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|   G6|       S|  Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55| C103|       S|  Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05| null|       S|    Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275| null|       S|    Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542| null|       S|  Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0| null|       S|   Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125| null|       Q|Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0| null|       S|    Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0| null|       S|   Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225| null|       C|   Mrs|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked=combined.na.fill('S',subset=['embarked'])\n",
    "grouped_Embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEcdV5Vb_qR_"
   },
   "source": [
    "## **Preprocessing Cabin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQzPs7tqhpA"
   },
   "source": [
    "**Replace \"cabin\" column with first char from the string:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "4b6L5pK0_nQz"
   },
   "outputs": [],
   "source": [
    "firstChar = F.udf(lambda word:word[0])\n",
    "grouped_Embarked=grouped_Embarked.withColumn('cabin',firstChar(F.col('cabin')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H8XshnYj4k2"
   },
   "source": [
    "**Show the result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|              22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|              38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|              26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|              35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|              35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.079501879699244|    0|    0|          330877| 8.4583|    U|       Q|    Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|              54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|               2.0|    3|    1|          349909| 21.075|    U|       S|Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|              27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|              14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|               4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|              58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|              20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|              14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|              55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|          382652| 29.125|    U|       Q|Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.079501879699244|    0|    0|          244373|   13.0|    U|       S|    Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|              31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.079501879699244|    0|    0|            2649|  7.225|    U|       C|   Mrs|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "gJUQwnG1Oj2U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, cabin='U', Embarked='S', Title='Mr')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_Embarked.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzSDsWsUj9Im"
   },
   "source": [
    "**Create the temporary view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "MR7CXTY7_tMJ"
   },
   "outputs": [],
   "source": [
    "grouped_Embarked.createTempView('temb2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7lfQFkrLlN"
   },
   "source": [
    "**Select \"Cabin\" column, count \"Cabin\" column, Group by \"Cabin\" column, Order By count DESC**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "A0tZG_mvrKXv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Cabin|count|\n",
      "+-----+-----+\n",
      "|    U| 1021|\n",
      "|    C|   82|\n",
      "|    B|   77|\n",
      "|    D|   52|\n",
      "|    E|   51|\n",
      "|    A|   23|\n",
      "|    F|   18|\n",
      "|    G|    4|\n",
      "|    T|    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Cabin, count(Cabin) as count from temb2 group by (cabin) order by count DESC').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GR6j0LOsB4y"
   },
   "source": [
    "**Fill missing values with \"U\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "mwq5CHEz_up_"
   },
   "outputs": [],
   "source": [
    "grouped_Embarked=grouped_Embarked.na.fill('U',subset=['cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRnhA_5-0Hi4"
   },
   "source": [
    "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RIKlOX71GQ-"
   },
   "source": [
    "**StringIndexer(inputCol=None, outputCol=None)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "odhuI2EHKuCm"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder,VectorAssembler\n",
    "stringIndexer= StringIndexer(inputCols=['Sex','Ticket','cabin','Embarked','Title'],outputCols=['Sex_index','Ticket_index','cabin_index','Embarked_index','Title_index'],handleInvalid='skip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DECL9yCK3JZ"
   },
   "source": [
    "**OneHotEncoder(inputCols=None, outputCols=None)**\n",
    "\n",
    "A one-hot encoder that maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. For example with 5 categories, an input value of 2.0 would map to an output vector of [0.0, 0.0, 1.0, 0.0]. The last category is not included by default (configurable via dropLast), because it makes the vector entries sum up to one, and hence linearly dependent. So an input value of 4.0 maps to [0.0, 0.0, 0.0, 0.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "tiAjDEy1LBhz"
   },
   "outputs": [],
   "source": [
    "one_hot_encoder= OneHotEncoder(inputCols=['Sex_index','Ticket_index','cabin_index','Embarked_index','Title_index'],outputCols=['Sex_ohe','Ticket_ohe','cabin_ohe','Embarked_ohe','Title_ohe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FsiLsd9452v"
   },
   "source": [
    "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None). A feature transformer that merges multiple columns into a vector column.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "BuytKk0hLE6p"
   },
   "outputs": [],
   "source": [
    "assemblerInputs=['Sex_ohe','Ticket_ohe','cabin_ohe','Embarked_ohe','Title_ohe','Pclass','Age','SibSp','Parch','Fare']\n",
    "\n",
    "vecAssembler= VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8DeZfh7JIo"
   },
   "source": [
    "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "8C11xf1iAzKp"
   },
   "outputs": [],
   "source": [
    "x_train, X_test = grouped_Embarked.randomSplit([.8,.2],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c_Hf_b0R12"
   },
   "source": [
    "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJQvmFai72O7"
   },
   "source": [
    "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "YnpmZqlTLPGq"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier \n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "rf=RandomForestClassifier(featuresCol='features',labelCol='Survived')\n",
    "\n",
    "pipline=Pipeline(stages=[stringIndexer,one_hot_encoder,vecAssembler,rf])\n",
    "piplineModel=pipline.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = piplineModel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSXEI8-r8bKY"
   },
   "source": [
    "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "Rl0UAKCaBDO-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7865168539325843"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluatore=MulticlassClassificationEvaluator(labelCol='Survived',predictionCol='prediction',metricName='accuracy')\n",
    "acc=evaluatore.evaluate(predDF)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO6_R1zJ9R1R"
   },
   "source": [
    "**When you are finished send the project via Google classroom**\n",
    "**Please let me know if you have any questions.**\n",
    "* nabieh.mostafa@yahoo.com\n",
    "* +201015197566 (Whatsapp)\n",
    "\n",
    "**Don't Hate me, I push you to learn**\n",
    "\n",
    "**I will help you to become an awesome data engineer.**\n",
    "\n",
    "**Why did I say that \"Data Engineer\"?**\n",
    "\n",
    "**Tricky question, but an optional question, if you would like to know the answer, ask me.**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical_work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
